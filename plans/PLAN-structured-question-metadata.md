# PLAN: Structured Question Metadata for Ontology Updates

## Problem Statement

Ontology questions currently contain:
- `text`: The question itself
- `category`: General category (enumeration, relationship, terminology, etc.)
- `affects`: Tables/columns the question is about
- `priority`, `is_required`: Importance indicators

**Missing:** Explicit guidance on HOW to answer the question - what tool to use, what parameters to provide, what format is expected.

This causes:
1. **MCP agents** must infer the right tool and parameters through trial and error
2. **Admin UI LLM** must guess how to parse natural language into structured updates
3. **Inconsistent answers** - different responders may update different fields

## Solution

Extend the question schema to include **answer schema** - structured metadata that specifies exactly how the answer should be provided and applied.

## Schema Changes

### New Fields on `OntologyQuestion`

```go
type OntologyQuestion struct {
    // ... existing fields ...

    // Answer guidance - generated by the question-generating LLM
    AnswerSchema *AnswerSchema `json:"answer_schema,omitempty"`
}

type AnswerSchema struct {
    // Which tool/action to use
    TargetTool string `json:"target_tool"` // "update_column", "update_entity", "update_glossary_term", etc.

    // Pre-filled parameters (known from question context)
    FixedParams map[string]any `json:"fixed_params,omitempty"` // e.g., {"table": "billing_transactions", "column": "transaction_state"}

    // Parameters the answer should provide
    RequiredParams []ParamSpec `json:"required_params"`
    OptionalParams []ParamSpec `json:"optional_params,omitempty"`

    // Human-readable guidance
    AnswerHint string `json:"answer_hint,omitempty"` // "List the meaning of each integer value (0-7)"

    // Example answer (for humans and LLM parsing)
    ExampleAnswer string `json:"example_answer,omitempty"` // "0=Pending, 1=Started, 2=Completed..."
}

type ParamSpec struct {
    Name        string `json:"name"`        // "enum_values"
    Type        string `json:"type"`        // "string", "string[]", "object[]"
    Description string `json:"description"` // "List of values with descriptions"
    Format      string `json:"format,omitempty"` // "value - description" or "value: description"
    Example     any    `json:"example,omitempty"` // ["0 - Pending", "1 - Active"]
}
```

### Database Migration

```sql
ALTER TABLE engine_ontology_questions
ADD COLUMN answer_schema JSONB;
```

## Question Generation Changes

### Current Flow
```
Schema → LLM → Questions with text + category + affects
```

### New Flow
```
Schema → LLM → Questions with text + category + affects + answer_schema
```

### Updated LLM Prompt for Question Generation

Add to the question generation system prompt:

```
For each question you generate, also specify the answer_schema that describes:
1. target_tool: Which MCP tool should be used to apply the answer
2. fixed_params: Parameters already known from context (table, column names)
3. required_params: What information the answer must provide
4. answer_hint: Brief guidance for the responder
5. example_answer: A sample answer format

Question categories map to tools as follows:
- "enumeration" → update_column with enum_values param
- "relationship" → update_column with entity/role params OR update_relationship
- "terminology" → update_glossary_term OR update_project_knowledge
- "data_quality" → update_column with description param
- "temporal" → update_column with description/semantic_type params
- "business_rules" → update_project_knowledge
```

## Example Questions with Answer Schema

### Example 1: Enum Question

**Before (current):**
```json
{
  "text": "What do the integer values 0-7 in billing_transactions.transaction_state represent?",
  "category": "enumeration",
  "affects": {"tables": ["billing_transactions"], "columns": ["transaction_state"]}
}
```

**After (with answer_schema):**
```json
{
  "text": "What do the integer values 0-7 in billing_transactions.transaction_state represent?",
  "category": "enumeration",
  "affects": {"tables": ["billing_transactions"], "columns": ["transaction_state"]},
  "answer_schema": {
    "target_tool": "update_column",
    "fixed_params": {
      "table": "billing_transactions",
      "column": "transaction_state"
    },
    "required_params": [
      {
        "name": "enum_values",
        "type": "string[]",
        "description": "Meaning of each integer value",
        "format": "value - description",
        "example": ["0 - Pending", "1 - Started", "2 - Completed"]
      }
    ],
    "optional_params": [
      {
        "name": "description",
        "type": "string",
        "description": "Overall description of what this state field tracks"
      }
    ],
    "answer_hint": "List what each value (0, 1, 2, 3, 4, 5, 6, 7) means in the transaction lifecycle",
    "example_answer": "0=Pending (initial state), 1=Started (transaction begun), 2=Completed..."
  }
}
```

### Example 2: FK/Relationship Question

**Before:**
```json
{
  "text": "What entity does host_id reference and what role does it play?",
  "category": "relationship",
  "affects": {"tables": ["engagements"], "columns": ["host_id"]}
}
```

**After:**
```json
{
  "text": "What entity does host_id reference and what role does it play?",
  "category": "relationship",
  "affects": {"tables": ["engagements"], "columns": ["host_id"]},
  "answer_schema": {
    "target_tool": "update_column",
    "fixed_params": {
      "table": "engagements",
      "column": "host_id"
    },
    "required_params": [
      {
        "name": "entity",
        "type": "string",
        "description": "Which entity this column references",
        "example": "User"
      },
      {
        "name": "role",
        "type": "string",
        "description": "The role this entity plays in this context",
        "example": "host"
      }
    ],
    "optional_params": [
      {
        "name": "description",
        "type": "string",
        "description": "Explanation of what this reference means"
      }
    ],
    "answer_hint": "Identify which entity (User, Account, etc.) and what role (host, visitor, owner, etc.)",
    "example_answer": "References User entity with role 'host' - the content creator receiving payment"
  }
}
```

### Example 3: Business Terminology Question

**Before:**
```json
{
  "text": "What is a 'Tik' in the context of this billing system?",
  "category": "terminology",
  "affects": {"tables": ["billing_transactions"], "columns": ["tiks", "amount_per_tik"]}
}
```

**After:**
```json
{
  "text": "What is a 'Tik' in the context of this billing system?",
  "category": "terminology",
  "affects": {"tables": ["billing_transactions"], "columns": ["tiks", "amount_per_tik"]},
  "answer_schema": {
    "target_tool": "update_project_knowledge",
    "fixed_params": {
      "category": "terminology"
    },
    "required_params": [
      {
        "name": "fact",
        "type": "string",
        "description": "Definition of the term",
        "example": "A Tik is 15 seconds of engagement time"
      }
    ],
    "optional_params": [
      {
        "name": "context",
        "type": "string",
        "description": "How this was discovered or verified"
      }
    ],
    "answer_hint": "Define what a Tik represents (time unit, billing unit, etc.) and its value",
    "example_answer": "A Tik is 15 seconds of engagement time - the fundamental billing unit"
  }
}
```

### Example 4: Soft Delete Pattern Question

**Before:**
```json
{
  "text": "What does a NULL vs non-NULL deleted_at indicate?",
  "category": "data_quality",
  "affects": {"tables": ["users"], "columns": ["deleted_at"]}
}
```

**After:**
```json
{
  "text": "What does a NULL vs non-NULL deleted_at indicate?",
  "category": "data_quality",
  "affects": {"tables": ["users"], "columns": ["deleted_at"]},
  "answer_schema": {
    "target_tool": "update_column",
    "fixed_params": {
      "table": "users",
      "column": "deleted_at"
    },
    "required_params": [
      {
        "name": "description",
        "type": "string",
        "description": "Explanation of NULL vs non-NULL semantics",
        "example": "Soft delete timestamp. NULL = active record, timestamp = deleted at that time."
      }
    ],
    "answer_hint": "Explain what NULL means vs having a timestamp value",
    "example_answer": "GORM soft delete pattern. NULL means the record is active; a timestamp means it was soft-deleted at that time."
  }
}
```

## Implementation Tasks

### Task 1: Add AnswerSchema to Models

**File:** `pkg/models/ontology_question.go`

Add the new structs and update `OntologyQuestion`.

**Acceptance criteria:**
- `AnswerSchema` struct defined with all fields
- `OntologyQuestion` includes optional `AnswerSchema` field
- JSON serialization works correctly

### Task 2: Database Migration

**File:** `migrations/XXXX_add_answer_schema.sql`

```sql
ALTER TABLE engine_ontology_questions
ADD COLUMN answer_schema JSONB;

COMMENT ON COLUMN engine_ontology_questions.answer_schema IS
'Structured metadata specifying how to answer this question - target tool, parameters, format';
```

**Acceptance criteria:**
- Migration runs successfully
- Existing questions unaffected (NULL answer_schema)
- New questions can store answer_schema

### Task 3: Update Question Generation LLM Prompt

**File:** `pkg/services/ontology_extractor.go` (or wherever questions are generated)

Update the prompt that generates questions to also produce `answer_schema`.

**Key additions to prompt:**
```
For each question, include an answer_schema object that specifies:
- target_tool: The MCP tool to use (update_column, update_entity, update_glossary_term, update_project_knowledge, update_relationship)
- fixed_params: Parameters already known (table name, column name from context)
- required_params: What the answer must provide
- answer_hint: Brief guidance for the responder
- example_answer: Sample answer format
```

**Acceptance criteria:**
- Generated questions include answer_schema
- answer_schema correctly maps question category to target tool
- fixed_params populated from question context

### Task 4: Update Question List Response

**File:** `pkg/mcp/tools/questions.go`

Include `answer_schema` in `list_ontology_questions` response.

```go
if q.AnswerSchema != nil {
    questionInfo["answer_schema"] = q.AnswerSchema
}
```

**Acceptance criteria:**
- MCP response includes answer_schema when present
- Backwards compatible (old questions without schema still work)

### Task 5: Update Admin UI Question Display

**File:** `ui/src/components/ontology/QuestionPanel.tsx`

Display answer guidance in the UI:
- Show answer_hint prominently
- Show example_answer as placeholder/guide
- Maybe pre-fill form fields from fixed_params

**Acceptance criteria:**
- Answer hint displayed to user
- Example answer shown as guidance
- Improved UX for answering questions

### Task 6: Update Admin Answer Processing

**File:** `pkg/services/ontology_builder.go`

Use answer_schema to guide LLM parsing of natural language answers:

```go
func (s *ontologyBuilderService) buildAnswerProcessingPrompt(question *models.OntologyQuestion, answer string) string {
    // ... existing prompt building ...

    if question.AnswerSchema != nil {
        prompt.WriteString("## Expected Answer Format\n\n")
        prompt.WriteString(fmt.Sprintf("Target tool: %s\n", question.AnswerSchema.TargetTool))
        prompt.WriteString(fmt.Sprintf("Fixed params: %v\n", question.AnswerSchema.FixedParams))
        prompt.WriteString("Required information:\n")
        for _, p := range question.AnswerSchema.RequiredParams {
            prompt.WriteString(fmt.Sprintf("- %s (%s): %s\n", p.Name, p.Type, p.Description))
        }
        if question.AnswerSchema.ExampleAnswer != "" {
            prompt.WriteString(fmt.Sprintf("\nExample answer: %s\n", question.AnswerSchema.ExampleAnswer))
        }
    }

    return prompt.String()
}
```

**Acceptance criteria:**
- LLM receives structured guidance on expected answer format
- Parsing accuracy improves for questions with answer_schema
- Fallback to current behavior for questions without schema

### Task 7: Backfill Existing Questions (Optional)

Create a one-time migration or admin tool to generate answer_schema for existing questions based on their category and affects fields.

**Acceptance criteria:**
- Existing questions can be enriched with answer_schema
- No data loss or corruption
- Can be run incrementally

## Testing Strategy

1. **Unit tests** for AnswerSchema serialization/deserialization
2. **Integration test** generating questions with answer_schema
3. **Manual test** answering questions via MCP with schema guidance
4. **Manual test** answering questions via Admin UI with schema guidance
5. **Compare** answer accuracy with/without answer_schema

## Success Metrics

| Metric | Before | After |
|--------|--------|-------|
| MCP agent knows correct tool | Inferred | Explicit in schema |
| MCP agent knows parameters | Inferred | Explicit in schema |
| Admin LLM parsing accuracy | ~70% | Target: 95% |
| Time to answer question | Variable | Reduced (clear guidance) |

## Rollout Plan

1. **Phase 1:** Add schema to models and DB (Tasks 1-2)
2. **Phase 2:** Update question generation (Task 3)
3. **Phase 3:** Update MCP response (Task 4) - MCP agents benefit
4. **Phase 4:** Update Admin UI (Task 5) - Human admins benefit
5. **Phase 5:** Update answer processing (Task 6) - LLM parsing improves
6. **Phase 6:** Backfill existing questions (Task 7) - Cleanup
